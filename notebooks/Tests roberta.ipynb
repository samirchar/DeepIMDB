{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fce2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "HOME = os.path.abspath('..')\n",
    "sys.path.append(HOME)\n",
    "os.chdir(HOME)\n",
    "import pandas as pd\n",
    "#!pip install transformers\n",
    "from transformers import RobertaConfig, RobertaModel,RobertaForSequenceClassification, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.roberta import RobertaPreTrainedModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3792dad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=1\n",
    "\n",
    "list(range(1, a+1, a//1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c5a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def process_text_data(data_:pd.DataFrame,text_col,na_filler = tokenizer.unk_token):\n",
    "    data = data_.copy()\n",
    "    data[text_col] = data[text_col].fillna(na_filler)\n",
    "    encodings = tokenizer(data[text_col].tolist(), padding=False, truncation=True)\n",
    "    return encodings\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "014136a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols =  ['Budget',\n",
    "             'averageRating',\n",
    "             'cast',\n",
    "             'countries',\n",
    "             'director',\n",
    "             'genres',\n",
    "             'imdb_id',\n",
    "             'languages',\n",
    "             'overview',\n",
    "             'production companies',\n",
    "             'release_date',\n",
    "             'revenue_worldwide_BOM',\n",
    "             'runtimeMinutes',\n",
    "             'title']\n",
    "\n",
    "\n",
    "train_ids = pd.read_csv('data/processed/train.csv',usecols=['imdb_id'])['imdb_id'].tolist()\n",
    "val_ids = pd.read_csv('data/processed/val.csv',usecols=['imdb_id'])['imdb_id'].tolist()\n",
    "test_ids = pd.read_csv('data/processed/test.csv',usecols=['imdb_id'])['imdb_id'].tolist()\n",
    "df = pd.read_csv('data/processed/df.csv',usecols = all_cols)\n",
    "\n",
    "TARGET_COL = 'averageRating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fecf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['imdb_id'].isin(train_ids)]\n",
    "val = df[df['imdb_id'].isin(val_ids)]\n",
    "test = df[df['imdb_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b33f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(train['imdb_id']) & set(val['imdb_id'])) == 0\n",
    "assert len(set(train['imdb_id']) & set(test['imdb_id'])) == 0\n",
    "assert len(set(test['imdb_id']) & set(val['imdb_id'])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71593ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(i) for i in train_encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d824b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imdb_id', 'runtimeMinutes', 'genres', 'cast', 'averageRating',\n",
       "       'numVotes', 'title', 'original_title', 'overview', 'release_date',\n",
       "       'poster_link', 'revenue_worldwide_BOM', 'director', 'countries',\n",
       "       'country codes', 'language codes', 'languages', 'Budget', 'cover url',\n",
       "       'production companies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb05ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d8611ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comedy, fantasy, romance'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['genres'][0].replace('|',', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9337da44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meg ryan, hugh jackman, liev schreiber'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['cast'][0].replace('|',', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6bd6242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comedy|fantasy|romance'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['genres'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7518c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Year', 'quarter', ...]].agg('-'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114317fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get train encodings\n",
    "train_encodings = process_text_data(train,'overview')\n",
    "val_encodings = process_text_data(val,'overview')\n",
    "test_encodings = process_text_data(test,'overview')\n",
    "\n",
    "#get labels\n",
    "train_labels = train[TARGET_COL].tolist()\n",
    "val_labels = val[TARGET_COL].tolist()\n",
    "test_labels = test[TARGET_COL].tolist()\n",
    "\n",
    "#Create dataset objects\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f6020a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>cast</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>poster_link</th>\n",
       "      <th>revenue_worldwide_BOM</th>\n",
       "      <th>director</th>\n",
       "      <th>countries</th>\n",
       "      <th>country codes</th>\n",
       "      <th>language codes</th>\n",
       "      <th>languages</th>\n",
       "      <th>Budget</th>\n",
       "      <th>cover url</th>\n",
       "      <th>production companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35423.0</td>\n",
       "      <td>118</td>\n",
       "      <td>comedy|fantasy|romance</td>\n",
       "      <td>meg ryan|hugh jackman|liev schreiber</td>\n",
       "      <td>6.4</td>\n",
       "      <td>83205.0</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>When her scientist ex-boyfriend discovers a po...</td>\n",
       "      <td>2001-12-25</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>76019048.0</td>\n",
       "      <td>james mangold</td>\n",
       "      <td>united states</td>\n",
       "      <td>us</td>\n",
       "      <td>en|fr</td>\n",
       "      <td>english|french</td>\n",
       "      <td>48000000.0</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNmNlN2...</td>\n",
       "      <td>konrad pictures|miramax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79285.0</td>\n",
       "      <td>88</td>\n",
       "      <td>adventure|horror|sci-fi</td>\n",
       "      <td>farrah fawcett|kirk douglas|harvey keitel</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9337.0</td>\n",
       "      <td>Saturn 3</td>\n",
       "      <td>Saturn 3</td>\n",
       "      <td>In the future, Earth is overcrowded and the po...</td>\n",
       "      <td>1980-02-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>stanley donen|john barry</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>gb</td>\n",
       "      <td>en</td>\n",
       "      <td>english</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BOGU1MD...</td>\n",
       "      <td>itc films|elliott kastner productions|transcon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79302.0</td>\n",
       "      <td>90</td>\n",
       "      <td>comedy</td>\n",
       "      <td>nancy allen|mary davenport|kirk douglas</td>\n",
       "      <td>5.1</td>\n",
       "      <td>911.0</td>\n",
       "      <td>Home Movies</td>\n",
       "      <td>Home Movies</td>\n",
       "      <td>A cult guru urges a shy disciple to make life ...</td>\n",
       "      <td>1980-05-16</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>89134.0</td>\n",
       "      <td>brian de palma</td>\n",
       "      <td>united states</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>english</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNWY4ZD...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80339.0</td>\n",
       "      <td>88</td>\n",
       "      <td>comedy</td>\n",
       "      <td>robert hays|julie hagerty|leslie nielsen</td>\n",
       "      <td>7.7</td>\n",
       "      <td>231364.0</td>\n",
       "      <td>Airplane!</td>\n",
       "      <td>Airplane!</td>\n",
       "      <td>Alcoholic pilot, Ted Striker has developed a f...</td>\n",
       "      <td>1980-02-07</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>83453539.0</td>\n",
       "      <td>jim abrahams|david zucker|jerry zucker</td>\n",
       "      <td>united states</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>english</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZjA3Yj...</td>\n",
       "      <td>paramount pictures|howard w. koch productions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80360.0</td>\n",
       "      <td>102</td>\n",
       "      <td>horror|sci-fi|thriller</td>\n",
       "      <td>william hurt|blair brown|bob balaban</td>\n",
       "      <td>6.9</td>\n",
       "      <td>34558.0</td>\n",
       "      <td>Altered States</td>\n",
       "      <td>Altered States</td>\n",
       "      <td>A research scientist (William Hurt) explores t...</td>\n",
       "      <td>1980-12-25</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>19853892.0</td>\n",
       "      <td>ken russell</td>\n",
       "      <td>united states</td>\n",
       "      <td>us</td>\n",
       "      <td>en|es</td>\n",
       "      <td>english|spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BZTdkOT...</td>\n",
       "      <td>warner bros.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9259</th>\n",
       "      <td>1869514.0</td>\n",
       "      <td>115</td>\n",
       "      <td>comedy|music</td>\n",
       "      <td>guido kangur|roman baskin|harri kõrvits</td>\n",
       "      <td>5.4</td>\n",
       "      <td>282.0</td>\n",
       "      <td>Farts of Fury</td>\n",
       "      <td>Kormoranid ehk Nahkpükse ei pesta</td>\n",
       "      <td>Kaiser, the lead singer of a former rock group...</td>\n",
       "      <td>2011-03-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204395.0</td>\n",
       "      <td>andres maimik|rain tolk</td>\n",
       "      <td>estonia</td>\n",
       "      <td>ee</td>\n",
       "      <td>et|en</td>\n",
       "      <td>estonian|english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYTcyNz...</td>\n",
       "      <td>kuukulgur film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9265</th>\n",
       "      <td>1874412.0</td>\n",
       "      <td>90</td>\n",
       "      <td>adventure|animation|sci-fi</td>\n",
       "      <td>adam behr|bruce boxleitner|steve breen</td>\n",
       "      <td>4.5</td>\n",
       "      <td>246.0</td>\n",
       "      <td>AniMen - Triton Force</td>\n",
       "      <td>AniMen - Triton Force</td>\n",
       "      <td>Over time, the people residing on Swampland be...</td>\n",
       "      <td>2010-03-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>395220.0</td>\n",
       "      <td>xu kerr</td>\n",
       "      <td>china|united states</td>\n",
       "      <td>cn|us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjEyMT...</td>\n",
       "      <td>gorilla pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9388</th>\n",
       "      <td>1964479.0</td>\n",
       "      <td>120</td>\n",
       "      <td>documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.8</td>\n",
       "      <td>65.0</td>\n",
       "      <td>American Passages</td>\n",
       "      <td>American Passages</td>\n",
       "      <td>Initially, there's that moment of happiness: a...</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57450.0</td>\n",
       "      <td>ruth beckermann</td>\n",
       "      <td>austria</td>\n",
       "      <td>at</td>\n",
       "      <td>en</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYmE1Y2...</td>\n",
       "      <td>ruth beckermann filmproduktion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9538</th>\n",
       "      <td>2061665.0</td>\n",
       "      <td>103</td>\n",
       "      <td>drama</td>\n",
       "      <td>david rees|darren kelfkens|leandie du randt</td>\n",
       "      <td>3.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Egoli: The Movie</td>\n",
       "      <td>Egoli: The Movie</td>\n",
       "      <td>Niek and Joe share a history and a secret from...</td>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53736.0</td>\n",
       "      <td>bromley cawood</td>\n",
       "      <td>south africa</td>\n",
       "      <td>za</td>\n",
       "      <td>en|af</td>\n",
       "      <td>english|afrikaans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYzIyMD...</td>\n",
       "      <td>brigadiers franz marx films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>2382420.0</td>\n",
       "      <td>72</td>\n",
       "      <td>documentary</td>\n",
       "      <td>evan bayh|tucker carlson|noam chomsky</td>\n",
       "      <td>6.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Split: A Divided America</td>\n",
       "      <td>Split: A Divided America</td>\n",
       "      <td>The USA is in the grips of a rancorous partisa...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>kelly nyks</td>\n",
       "      <td>united states</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>english</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjE0ND...</td>\n",
       "      <td>pf pictures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8177 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         imdb_id runtimeMinutes                      genres  \\\n",
       "0        35423.0            118      comedy|fantasy|romance   \n",
       "1        79285.0             88     adventure|horror|sci-fi   \n",
       "2        79302.0             90                      comedy   \n",
       "3        80339.0             88                      comedy   \n",
       "4        80360.0            102      horror|sci-fi|thriller   \n",
       "...          ...            ...                         ...   \n",
       "9259   1869514.0            115                comedy|music   \n",
       "9265   1874412.0             90  adventure|animation|sci-fi   \n",
       "9388   1964479.0            120                 documentary   \n",
       "9538   2061665.0            103                       drama   \n",
       "10019  2382420.0             72                 documentary   \n",
       "\n",
       "                                              cast  averageRating  numVotes  \\\n",
       "0             meg ryan|hugh jackman|liev schreiber            6.4   83205.0   \n",
       "1        farrah fawcett|kirk douglas|harvey keitel            5.1    9337.0   \n",
       "2          nancy allen|mary davenport|kirk douglas            5.1     911.0   \n",
       "3         robert hays|julie hagerty|leslie nielsen            7.7  231364.0   \n",
       "4             william hurt|blair brown|bob balaban            6.9   34558.0   \n",
       "...                                            ...            ...       ...   \n",
       "9259       guido kangur|roman baskin|harri kõrvits            5.4     282.0   \n",
       "9265        adam behr|bruce boxleitner|steve breen            4.5     246.0   \n",
       "9388                                           NaN            6.8      65.0   \n",
       "9538   david rees|darren kelfkens|leandie du randt            3.5      11.0   \n",
       "10019        evan bayh|tucker carlson|noam chomsky            6.7      17.0   \n",
       "\n",
       "                          title                     original_title  \\\n",
       "0                Kate & Leopold                     Kate & Leopold   \n",
       "1                      Saturn 3                           Saturn 3   \n",
       "2                   Home Movies                        Home Movies   \n",
       "3                     Airplane!                          Airplane!   \n",
       "4                Altered States                     Altered States   \n",
       "...                         ...                                ...   \n",
       "9259              Farts of Fury  Kormoranid ehk Nahkpükse ei pesta   \n",
       "9265      AniMen - Triton Force              AniMen - Triton Force   \n",
       "9388          American Passages                  American Passages   \n",
       "9538           Egoli: The Movie                   Egoli: The Movie   \n",
       "10019  Split: A Divided America           Split: A Divided America   \n",
       "\n",
       "                                                overview release_date  \\\n",
       "0      When her scientist ex-boyfriend discovers a po...   2001-12-25   \n",
       "1      In the future, Earth is overcrowded and the po...   1980-02-15   \n",
       "2      A cult guru urges a shy disciple to make life ...   1980-05-16   \n",
       "3      Alcoholic pilot, Ted Striker has developed a f...   1980-02-07   \n",
       "4      A research scientist (William Hurt) explores t...   1980-12-25   \n",
       "...                                                  ...          ...   \n",
       "9259   Kaiser, the lead singer of a former rock group...   2011-03-17   \n",
       "9265   Over time, the people residing on Swampland be...   2010-03-24   \n",
       "9388   Initially, there's that moment of happiness: a...   2011-03-31   \n",
       "9538   Niek and Joe share a history and a secret from...   2010-06-16   \n",
       "10019  The USA is in the grips of a rancorous partisa...   2008-01-01   \n",
       "\n",
       "                                             poster_link  \\\n",
       "0      https://images-na.ssl-images-amazon.com/images...   \n",
       "1                                                    NaN   \n",
       "2      https://images-na.ssl-images-amazon.com/images...   \n",
       "3      https://images-na.ssl-images-amazon.com/images...   \n",
       "4      https://images-na.ssl-images-amazon.com/images...   \n",
       "...                                                  ...   \n",
       "9259                                                 NaN   \n",
       "9265                                                 NaN   \n",
       "9388                                                 NaN   \n",
       "9538                                                 NaN   \n",
       "10019                                                NaN   \n",
       "\n",
       "       revenue_worldwide_BOM                                director  \\\n",
       "0                 76019048.0                           james mangold   \n",
       "1                  9000000.0                stanley donen|john barry   \n",
       "2                    89134.0                          brian de palma   \n",
       "3                 83453539.0  jim abrahams|david zucker|jerry zucker   \n",
       "4                 19853892.0                             ken russell   \n",
       "...                      ...                                     ...   \n",
       "9259                204395.0                 andres maimik|rain tolk   \n",
       "9265                395220.0                                 xu kerr   \n",
       "9388                 57450.0                         ruth beckermann   \n",
       "9538                 53736.0                          bromley cawood   \n",
       "10019                 2000.0                              kelly nyks   \n",
       "\n",
       "                 countries country codes language codes          languages  \\\n",
       "0            united states            us          en|fr     english|french   \n",
       "1           united kingdom            gb             en            english   \n",
       "2            united states            us             en            english   \n",
       "3            united states            us             en            english   \n",
       "4            united states            us          en|es    english|spanish   \n",
       "...                    ...           ...            ...                ...   \n",
       "9259               estonia            ee          et|en   estonian|english   \n",
       "9265   china|united states         cn|us            NaN                NaN   \n",
       "9388               austria            at             en            english   \n",
       "9538          south africa            za          en|af  english|afrikaans   \n",
       "10019        united states            us             en            english   \n",
       "\n",
       "           Budget                                          cover url  \\\n",
       "0      48000000.0  https://m.media-amazon.com/images/M/MV5BNmNlN2...   \n",
       "1      10000000.0  https://m.media-amazon.com/images/M/MV5BOGU1MD...   \n",
       "2        400000.0  https://m.media-amazon.com/images/M/MV5BNWY4ZD...   \n",
       "3       3500000.0  https://m.media-amazon.com/images/M/MV5BZjA3Yj...   \n",
       "4             NaN  https://m.media-amazon.com/images/M/MV5BZTdkOT...   \n",
       "...           ...                                                ...   \n",
       "9259          NaN  https://m.media-amazon.com/images/M/MV5BYTcyNz...   \n",
       "9265          NaN  https://m.media-amazon.com/images/M/MV5BMjEyMT...   \n",
       "9388          NaN  https://m.media-amazon.com/images/M/MV5BYmE1Y2...   \n",
       "9538          NaN  https://m.media-amazon.com/images/M/MV5BYzIyMD...   \n",
       "10019    150000.0  https://m.media-amazon.com/images/M/MV5BMjE0ND...   \n",
       "\n",
       "                                    production companies  \n",
       "0                                konrad pictures|miramax  \n",
       "1      itc films|elliott kastner productions|transcon...  \n",
       "2                                                    NaN  \n",
       "3          paramount pictures|howard w. koch productions  \n",
       "4                                           warner bros.  \n",
       "...                                                  ...  \n",
       "9259                                      kuukulgur film  \n",
       "9265                                    gorilla pictures  \n",
       "9388                      ruth beckermann filmproduktion  \n",
       "9538                         brigadiers franz marx films  \n",
       "10019                                        pf pictures  \n",
       "\n",
       "[8177 rows x 20 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0a4407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in train_encodings['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b694349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\",\n",
    "                                                         problem_type='regression',\n",
    "                                                         num_labels=1\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e001fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /Users/samirchar/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /Users/samirchar/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "model_init should have 0 or 1 argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d1dee03b469f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#compute_metrics=compute_metrics,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_model_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`Trainer` requires either a `model` or `model_init` argument\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcall_model_init\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_init should have 0 or 1 argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: model_init should have 0 or 1 argument."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  learning_rate = 5e-05,\n",
    "                                  weight_decay = 0.0,\n",
    "                                  num_train_epochs = 3)\n",
    "\n",
    "def get_model():\n",
    "    return RobertaForSequenceClassification.from_pretrained(\"roberta-base\",\n",
    "                                                         problem_type='regression',\n",
    "                                                         num_labels=1\n",
    "                                                        )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=get_model(),\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c5fc3a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight True\n",
      "roberta.embeddings.position_embeddings.weight True\n",
      "roberta.embeddings.token_type_embeddings.weight True\n",
      "roberta.embeddings.LayerNorm.weight True\n",
      "roberta.embeddings.LayerNorm.bias True\n",
      "roberta.encoder.layer.0.attention.self.query.weight True\n",
      "roberta.encoder.layer.0.attention.self.query.bias True\n",
      "roberta.encoder.layer.0.attention.self.key.weight True\n",
      "roberta.encoder.layer.0.attention.self.key.bias True\n",
      "roberta.encoder.layer.0.attention.self.value.weight True\n",
      "roberta.encoder.layer.0.attention.self.value.bias True\n",
      "roberta.encoder.layer.0.attention.output.dense.weight True\n",
      "roberta.encoder.layer.0.attention.output.dense.bias True\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.0.intermediate.dense.weight True\n",
      "roberta.encoder.layer.0.intermediate.dense.bias True\n",
      "roberta.encoder.layer.0.output.dense.weight True\n",
      "roberta.encoder.layer.0.output.dense.bias True\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.1.attention.self.query.weight True\n",
      "roberta.encoder.layer.1.attention.self.query.bias True\n",
      "roberta.encoder.layer.1.attention.self.key.weight True\n",
      "roberta.encoder.layer.1.attention.self.key.bias True\n",
      "roberta.encoder.layer.1.attention.self.value.weight True\n",
      "roberta.encoder.layer.1.attention.self.value.bias True\n",
      "roberta.encoder.layer.1.attention.output.dense.weight True\n",
      "roberta.encoder.layer.1.attention.output.dense.bias True\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.1.intermediate.dense.weight True\n",
      "roberta.encoder.layer.1.intermediate.dense.bias True\n",
      "roberta.encoder.layer.1.output.dense.weight True\n",
      "roberta.encoder.layer.1.output.dense.bias True\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.2.attention.self.query.weight True\n",
      "roberta.encoder.layer.2.attention.self.query.bias True\n",
      "roberta.encoder.layer.2.attention.self.key.weight True\n",
      "roberta.encoder.layer.2.attention.self.key.bias True\n",
      "roberta.encoder.layer.2.attention.self.value.weight True\n",
      "roberta.encoder.layer.2.attention.self.value.bias True\n",
      "roberta.encoder.layer.2.attention.output.dense.weight True\n",
      "roberta.encoder.layer.2.attention.output.dense.bias True\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.2.intermediate.dense.weight True\n",
      "roberta.encoder.layer.2.intermediate.dense.bias True\n",
      "roberta.encoder.layer.2.output.dense.weight True\n",
      "roberta.encoder.layer.2.output.dense.bias True\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.3.attention.self.query.weight True\n",
      "roberta.encoder.layer.3.attention.self.query.bias True\n",
      "roberta.encoder.layer.3.attention.self.key.weight True\n",
      "roberta.encoder.layer.3.attention.self.key.bias True\n",
      "roberta.encoder.layer.3.attention.self.value.weight True\n",
      "roberta.encoder.layer.3.attention.self.value.bias True\n",
      "roberta.encoder.layer.3.attention.output.dense.weight True\n",
      "roberta.encoder.layer.3.attention.output.dense.bias True\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.3.intermediate.dense.weight True\n",
      "roberta.encoder.layer.3.intermediate.dense.bias True\n",
      "roberta.encoder.layer.3.output.dense.weight True\n",
      "roberta.encoder.layer.3.output.dense.bias True\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.4.attention.self.query.weight True\n",
      "roberta.encoder.layer.4.attention.self.query.bias True\n",
      "roberta.encoder.layer.4.attention.self.key.weight True\n",
      "roberta.encoder.layer.4.attention.self.key.bias True\n",
      "roberta.encoder.layer.4.attention.self.value.weight True\n",
      "roberta.encoder.layer.4.attention.self.value.bias True\n",
      "roberta.encoder.layer.4.attention.output.dense.weight True\n",
      "roberta.encoder.layer.4.attention.output.dense.bias True\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.4.intermediate.dense.weight True\n",
      "roberta.encoder.layer.4.intermediate.dense.bias True\n",
      "roberta.encoder.layer.4.output.dense.weight True\n",
      "roberta.encoder.layer.4.output.dense.bias True\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.5.attention.self.query.weight True\n",
      "roberta.encoder.layer.5.attention.self.query.bias True\n",
      "roberta.encoder.layer.5.attention.self.key.weight True\n",
      "roberta.encoder.layer.5.attention.self.key.bias True\n",
      "roberta.encoder.layer.5.attention.self.value.weight True\n",
      "roberta.encoder.layer.5.attention.self.value.bias True\n",
      "roberta.encoder.layer.5.attention.output.dense.weight True\n",
      "roberta.encoder.layer.5.attention.output.dense.bias True\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.5.intermediate.dense.weight True\n",
      "roberta.encoder.layer.5.intermediate.dense.bias True\n",
      "roberta.encoder.layer.5.output.dense.weight True\n",
      "roberta.encoder.layer.5.output.dense.bias True\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.6.attention.self.query.weight True\n",
      "roberta.encoder.layer.6.attention.self.query.bias True\n",
      "roberta.encoder.layer.6.attention.self.key.weight True\n",
      "roberta.encoder.layer.6.attention.self.key.bias True\n",
      "roberta.encoder.layer.6.attention.self.value.weight True\n",
      "roberta.encoder.layer.6.attention.self.value.bias True\n",
      "roberta.encoder.layer.6.attention.output.dense.weight True\n",
      "roberta.encoder.layer.6.attention.output.dense.bias True\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.6.intermediate.dense.weight True\n",
      "roberta.encoder.layer.6.intermediate.dense.bias True\n",
      "roberta.encoder.layer.6.output.dense.weight True\n",
      "roberta.encoder.layer.6.output.dense.bias True\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.7.attention.self.query.weight True\n",
      "roberta.encoder.layer.7.attention.self.query.bias True\n",
      "roberta.encoder.layer.7.attention.self.key.weight True\n",
      "roberta.encoder.layer.7.attention.self.key.bias True\n",
      "roberta.encoder.layer.7.attention.self.value.weight True\n",
      "roberta.encoder.layer.7.attention.self.value.bias True\n",
      "roberta.encoder.layer.7.attention.output.dense.weight True\n",
      "roberta.encoder.layer.7.attention.output.dense.bias True\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.7.intermediate.dense.weight True\n",
      "roberta.encoder.layer.7.intermediate.dense.bias True\n",
      "roberta.encoder.layer.7.output.dense.weight True\n",
      "roberta.encoder.layer.7.output.dense.bias True\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.8.attention.self.query.weight True\n",
      "roberta.encoder.layer.8.attention.self.query.bias True\n",
      "roberta.encoder.layer.8.attention.self.key.weight True\n",
      "roberta.encoder.layer.8.attention.self.key.bias True\n",
      "roberta.encoder.layer.8.attention.self.value.weight True\n",
      "roberta.encoder.layer.8.attention.self.value.bias True\n",
      "roberta.encoder.layer.8.attention.output.dense.weight True\n",
      "roberta.encoder.layer.8.attention.output.dense.bias True\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.8.intermediate.dense.weight True\n",
      "roberta.encoder.layer.8.intermediate.dense.bias True\n",
      "roberta.encoder.layer.8.output.dense.weight True\n",
      "roberta.encoder.layer.8.output.dense.bias True\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.9.attention.self.query.weight True\n",
      "roberta.encoder.layer.9.attention.self.query.bias True\n",
      "roberta.encoder.layer.9.attention.self.key.weight True\n",
      "roberta.encoder.layer.9.attention.self.key.bias True\n",
      "roberta.encoder.layer.9.attention.self.value.weight True\n",
      "roberta.encoder.layer.9.attention.self.value.bias True\n",
      "roberta.encoder.layer.9.attention.output.dense.weight True\n",
      "roberta.encoder.layer.9.attention.output.dense.bias True\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.9.intermediate.dense.weight True\n",
      "roberta.encoder.layer.9.intermediate.dense.bias True\n",
      "roberta.encoder.layer.9.output.dense.weight True\n",
      "roberta.encoder.layer.9.output.dense.bias True\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.10.attention.self.query.weight True\n",
      "roberta.encoder.layer.10.attention.self.query.bias True\n",
      "roberta.encoder.layer.10.attention.self.key.weight True\n",
      "roberta.encoder.layer.10.attention.self.key.bias True\n",
      "roberta.encoder.layer.10.attention.self.value.weight True\n",
      "roberta.encoder.layer.10.attention.self.value.bias True\n",
      "roberta.encoder.layer.10.attention.output.dense.weight True\n",
      "roberta.encoder.layer.10.attention.output.dense.bias True\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.10.intermediate.dense.weight True\n",
      "roberta.encoder.layer.10.intermediate.dense.bias True\n",
      "roberta.encoder.layer.10.output.dense.weight True\n",
      "roberta.encoder.layer.10.output.dense.bias True\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.11.attention.self.query.weight True\n",
      "roberta.encoder.layer.11.attention.self.query.bias True\n",
      "roberta.encoder.layer.11.attention.self.key.weight True\n",
      "roberta.encoder.layer.11.attention.self.key.bias True\n",
      "roberta.encoder.layer.11.attention.self.value.weight True\n",
      "roberta.encoder.layer.11.attention.self.value.bias True\n",
      "roberta.encoder.layer.11.attention.output.dense.weight True\n",
      "roberta.encoder.layer.11.attention.output.dense.bias True\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias True\n",
      "roberta.encoder.layer.11.intermediate.dense.weight True\n",
      "roberta.encoder.layer.11.intermediate.dense.bias True\n",
      "roberta.encoder.layer.11.output.dense.weight True\n",
      "roberta.encoder.layer.11.output.dense.bias True\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight True\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias True\n",
      "classifier.dense.weight True\n",
      "classifier.dense.bias True\n",
      "classifier.out_proj.weight True\n",
      "classifier.out_proj.bias True\n"
     ]
    }
   ],
   "source": [
    "18750->500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ddfbb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18750/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b389271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.88"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1533*500/18750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4658f9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.390243902439025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1533/41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a54f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1476, -0.0365,  0.0753,  ..., -0.0023,  0.0172, -0.0016],\n",
       "        [ 0.0156,  0.0076, -0.0118,  ..., -0.0022,  0.0081, -0.0156],\n",
       "        [-0.0347, -0.0873, -0.0180,  ...,  0.1174, -0.0098, -0.0355],\n",
       "        ...,\n",
       "        [ 0.0304,  0.0504, -0.0307,  ...,  0.0377,  0.0096,  0.0084],\n",
       "        [ 0.0623, -0.0596,  0.0307,  ..., -0.0920,  0.1080, -0.0183],\n",
       "        [ 0.1259, -0.0145,  0.0332,  ...,  0.0121,  0.0342,  0.0168]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.named_parameters())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "158279f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 8177\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3069\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='3069' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   5/3069 02:11 < 37:18:56, 0.02 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e1afbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(c,a,b):\n",
    "    print(c,a,b)\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "188c0c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 1 22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo(123,**{'a':1,'b':22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e706105c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid format specifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a259a585913f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34mf\"**{'a':10,'b':22}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Invalid format specifier"
     ]
    }
   ],
   "source": [
    "f\"**{'a':10,'b':22}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5f11066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gammas = [0.95,0.99]\n",
    "lrs = [0.05,0.1,0.2]\n",
    "eps_start = np.arange(.7,1.1,.1).tolist()\n",
    "eps_end = [0.001,0.01,0.1]\n",
    "decays = [.99,.999,.9999]\n",
    "repeats = 5\n",
    "\n",
    "hparams = [lrs,eps_start,eps_end,gammas,decays]\n",
    "\n",
    "combs = list(product(*[range(len(i)) for i in hparams],range(repeats)))\n",
    "scores = np.zeros((*[len(i) for i in hparams],repeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b2954f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.05, 0.1, 0.2],\n",
       " [0.7,\n",
       "  0.7999999999999999,\n",
       "  0.8999999999999999,\n",
       "  0.9999999999999999,\n",
       "  1.0999999999999999],\n",
       " [0.001, 0.01, 0.1],\n",
       " [0.95, 0.99],\n",
       " [0.99, 0.999, 0.9999]]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7e155322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 0, 1),\n",
       " (0, 0, 0, 0, 0, 2),\n",
       " (0, 0, 0, 0, 0, 3),\n",
       " (0, 0, 0, 0, 0, 4),\n",
       " (0, 0, 0, 0, 1, 0),\n",
       " (0, 0, 0, 0, 1, 1),\n",
       " (0, 0, 0, 0, 1, 2),\n",
       " (0, 0, 0, 0, 1, 3),\n",
       " (0, 0, 0, 0, 1, 4),\n",
       " (0, 0, 0, 0, 2, 0),\n",
       " (0, 0, 0, 0, 2, 1),\n",
       " (0, 0, 0, 0, 2, 2),\n",
       " (0, 0, 0, 0, 2, 3),\n",
       " (0, 0, 0, 0, 2, 4),\n",
       " (0, 0, 0, 1, 0, 0),\n",
       " (0, 0, 0, 1, 0, 1),\n",
       " (0, 0, 0, 1, 0, 2),\n",
       " (0, 0, 0, 1, 0, 3),\n",
       " (0, 0, 0, 1, 0, 4),\n",
       " (0, 0, 0, 1, 1, 0),\n",
       " (0, 0, 0, 1, 1, 1),\n",
       " (0, 0, 0, 1, 1, 2),\n",
       " (0, 0, 0, 1, 1, 3),\n",
       " (0, 0, 0, 1, 1, 4),\n",
       " (0, 0, 0, 1, 2, 0),\n",
       " (0, 0, 0, 1, 2, 1),\n",
       " (0, 0, 0, 1, 2, 2),\n",
       " (0, 0, 0, 1, 2, 3),\n",
       " (0, 0, 0, 1, 2, 4),\n",
       " (0, 0, 1, 0, 0, 0),\n",
       " (0, 0, 1, 0, 0, 1),\n",
       " (0, 0, 1, 0, 0, 2),\n",
       " (0, 0, 1, 0, 0, 3),\n",
       " (0, 0, 1, 0, 0, 4),\n",
       " (0, 0, 1, 0, 1, 0),\n",
       " (0, 0, 1, 0, 1, 1),\n",
       " (0, 0, 1, 0, 1, 2),\n",
       " (0, 0, 1, 0, 1, 3),\n",
       " (0, 0, 1, 0, 1, 4),\n",
       " (0, 0, 1, 0, 2, 0),\n",
       " (0, 0, 1, 0, 2, 1),\n",
       " (0, 0, 1, 0, 2, 2),\n",
       " (0, 0, 1, 0, 2, 3),\n",
       " (0, 0, 1, 0, 2, 4),\n",
       " (0, 0, 1, 1, 0, 0),\n",
       " (0, 0, 1, 1, 0, 1),\n",
       " (0, 0, 1, 1, 0, 2),\n",
       " (0, 0, 1, 1, 0, 3),\n",
       " (0, 0, 1, 1, 0, 4),\n",
       " (0, 0, 1, 1, 1, 0),\n",
       " (0, 0, 1, 1, 1, 1),\n",
       " (0, 0, 1, 1, 1, 2),\n",
       " (0, 0, 1, 1, 1, 3),\n",
       " (0, 0, 1, 1, 1, 4),\n",
       " (0, 0, 1, 1, 2, 0),\n",
       " (0, 0, 1, 1, 2, 1),\n",
       " (0, 0, 1, 1, 2, 2),\n",
       " (0, 0, 1, 1, 2, 3),\n",
       " (0, 0, 1, 1, 2, 4),\n",
       " (0, 0, 2, 0, 0, 0),\n",
       " (0, 0, 2, 0, 0, 1),\n",
       " (0, 0, 2, 0, 0, 2),\n",
       " (0, 0, 2, 0, 0, 3),\n",
       " (0, 0, 2, 0, 0, 4),\n",
       " (0, 0, 2, 0, 1, 0),\n",
       " (0, 0, 2, 0, 1, 1),\n",
       " (0, 0, 2, 0, 1, 2),\n",
       " (0, 0, 2, 0, 1, 3),\n",
       " (0, 0, 2, 0, 1, 4),\n",
       " (0, 0, 2, 0, 2, 0),\n",
       " (0, 0, 2, 0, 2, 1),\n",
       " (0, 0, 2, 0, 2, 2),\n",
       " (0, 0, 2, 0, 2, 3),\n",
       " (0, 0, 2, 0, 2, 4),\n",
       " (0, 0, 2, 1, 0, 0),\n",
       " (0, 0, 2, 1, 0, 1),\n",
       " (0, 0, 2, 1, 0, 2),\n",
       " (0, 0, 2, 1, 0, 3),\n",
       " (0, 0, 2, 1, 0, 4),\n",
       " (0, 0, 2, 1, 1, 0),\n",
       " (0, 0, 2, 1, 1, 1),\n",
       " (0, 0, 2, 1, 1, 2),\n",
       " (0, 0, 2, 1, 1, 3),\n",
       " (0, 0, 2, 1, 1, 4),\n",
       " (0, 0, 2, 1, 2, 0),\n",
       " (0, 0, 2, 1, 2, 1),\n",
       " (0, 0, 2, 1, 2, 2),\n",
       " (0, 0, 2, 1, 2, 3),\n",
       " (0, 0, 2, 1, 2, 4),\n",
       " (0, 1, 0, 0, 0, 0),\n",
       " (0, 1, 0, 0, 0, 1),\n",
       " (0, 1, 0, 0, 0, 2),\n",
       " (0, 1, 0, 0, 0, 3),\n",
       " (0, 1, 0, 0, 0, 4),\n",
       " (0, 1, 0, 0, 1, 0),\n",
       " (0, 1, 0, 0, 1, 1),\n",
       " (0, 1, 0, 0, 1, 2),\n",
       " (0, 1, 0, 0, 1, 3),\n",
       " (0, 1, 0, 0, 1, 4),\n",
       " (0, 1, 0, 0, 2, 0),\n",
       " (0, 1, 0, 0, 2, 1),\n",
       " (0, 1, 0, 0, 2, 2),\n",
       " (0, 1, 0, 0, 2, 3),\n",
       " (0, 1, 0, 0, 2, 4),\n",
       " (0, 1, 0, 1, 0, 0),\n",
       " (0, 1, 0, 1, 0, 1),\n",
       " (0, 1, 0, 1, 0, 2),\n",
       " (0, 1, 0, 1, 0, 3),\n",
       " (0, 1, 0, 1, 0, 4),\n",
       " (0, 1, 0, 1, 1, 0),\n",
       " (0, 1, 0, 1, 1, 1),\n",
       " (0, 1, 0, 1, 1, 2),\n",
       " (0, 1, 0, 1, 1, 3),\n",
       " (0, 1, 0, 1, 1, 4),\n",
       " (0, 1, 0, 1, 2, 0),\n",
       " (0, 1, 0, 1, 2, 1),\n",
       " (0, 1, 0, 1, 2, 2),\n",
       " (0, 1, 0, 1, 2, 3),\n",
       " (0, 1, 0, 1, 2, 4),\n",
       " (0, 1, 1, 0, 0, 0),\n",
       " (0, 1, 1, 0, 0, 1),\n",
       " (0, 1, 1, 0, 0, 2),\n",
       " (0, 1, 1, 0, 0, 3),\n",
       " (0, 1, 1, 0, 0, 4),\n",
       " (0, 1, 1, 0, 1, 0),\n",
       " (0, 1, 1, 0, 1, 1),\n",
       " (0, 1, 1, 0, 1, 2),\n",
       " (0, 1, 1, 0, 1, 3),\n",
       " (0, 1, 1, 0, 1, 4),\n",
       " (0, 1, 1, 0, 2, 0),\n",
       " (0, 1, 1, 0, 2, 1),\n",
       " (0, 1, 1, 0, 2, 2),\n",
       " (0, 1, 1, 0, 2, 3),\n",
       " (0, 1, 1, 0, 2, 4),\n",
       " (0, 1, 1, 1, 0, 0),\n",
       " (0, 1, 1, 1, 0, 1),\n",
       " (0, 1, 1, 1, 0, 2),\n",
       " (0, 1, 1, 1, 0, 3),\n",
       " (0, 1, 1, 1, 0, 4),\n",
       " (0, 1, 1, 1, 1, 0),\n",
       " (0, 1, 1, 1, 1, 1),\n",
       " (0, 1, 1, 1, 1, 2),\n",
       " (0, 1, 1, 1, 1, 3),\n",
       " (0, 1, 1, 1, 1, 4),\n",
       " (0, 1, 1, 1, 2, 0),\n",
       " (0, 1, 1, 1, 2, 1),\n",
       " (0, 1, 1, 1, 2, 2),\n",
       " (0, 1, 1, 1, 2, 3),\n",
       " (0, 1, 1, 1, 2, 4),\n",
       " (0, 1, 2, 0, 0, 0),\n",
       " (0, 1, 2, 0, 0, 1),\n",
       " (0, 1, 2, 0, 0, 2),\n",
       " (0, 1, 2, 0, 0, 3),\n",
       " (0, 1, 2, 0, 0, 4),\n",
       " (0, 1, 2, 0, 1, 0),\n",
       " (0, 1, 2, 0, 1, 1),\n",
       " (0, 1, 2, 0, 1, 2),\n",
       " (0, 1, 2, 0, 1, 3),\n",
       " (0, 1, 2, 0, 1, 4),\n",
       " (0, 1, 2, 0, 2, 0),\n",
       " (0, 1, 2, 0, 2, 1),\n",
       " (0, 1, 2, 0, 2, 2),\n",
       " (0, 1, 2, 0, 2, 3),\n",
       " (0, 1, 2, 0, 2, 4),\n",
       " (0, 1, 2, 1, 0, 0),\n",
       " (0, 1, 2, 1, 0, 1),\n",
       " (0, 1, 2, 1, 0, 2),\n",
       " (0, 1, 2, 1, 0, 3),\n",
       " (0, 1, 2, 1, 0, 4),\n",
       " (0, 1, 2, 1, 1, 0),\n",
       " (0, 1, 2, 1, 1, 1),\n",
       " (0, 1, 2, 1, 1, 2),\n",
       " (0, 1, 2, 1, 1, 3),\n",
       " (0, 1, 2, 1, 1, 4),\n",
       " (0, 1, 2, 1, 2, 0),\n",
       " (0, 1, 2, 1, 2, 1),\n",
       " (0, 1, 2, 1, 2, 2),\n",
       " (0, 1, 2, 1, 2, 3),\n",
       " (0, 1, 2, 1, 2, 4),\n",
       " (0, 2, 0, 0, 0, 0),\n",
       " (0, 2, 0, 0, 0, 1),\n",
       " (0, 2, 0, 0, 0, 2),\n",
       " (0, 2, 0, 0, 0, 3),\n",
       " (0, 2, 0, 0, 0, 4),\n",
       " (0, 2, 0, 0, 1, 0),\n",
       " (0, 2, 0, 0, 1, 1),\n",
       " (0, 2, 0, 0, 1, 2),\n",
       " (0, 2, 0, 0, 1, 3),\n",
       " (0, 2, 0, 0, 1, 4),\n",
       " (0, 2, 0, 0, 2, 0),\n",
       " (0, 2, 0, 0, 2, 1),\n",
       " (0, 2, 0, 0, 2, 2),\n",
       " (0, 2, 0, 0, 2, 3),\n",
       " (0, 2, 0, 0, 2, 4),\n",
       " (0, 2, 0, 1, 0, 0),\n",
       " (0, 2, 0, 1, 0, 1),\n",
       " (0, 2, 0, 1, 0, 2),\n",
       " (0, 2, 0, 1, 0, 3),\n",
       " (0, 2, 0, 1, 0, 4),\n",
       " (0, 2, 0, 1, 1, 0),\n",
       " (0, 2, 0, 1, 1, 1),\n",
       " (0, 2, 0, 1, 1, 2),\n",
       " (0, 2, 0, 1, 1, 3),\n",
       " (0, 2, 0, 1, 1, 4),\n",
       " (0, 2, 0, 1, 2, 0),\n",
       " (0, 2, 0, 1, 2, 1),\n",
       " (0, 2, 0, 1, 2, 2),\n",
       " (0, 2, 0, 1, 2, 3),\n",
       " (0, 2, 0, 1, 2, 4),\n",
       " (0, 2, 1, 0, 0, 0),\n",
       " (0, 2, 1, 0, 0, 1),\n",
       " (0, 2, 1, 0, 0, 2),\n",
       " (0, 2, 1, 0, 0, 3),\n",
       " (0, 2, 1, 0, 0, 4),\n",
       " (0, 2, 1, 0, 1, 0),\n",
       " (0, 2, 1, 0, 1, 1),\n",
       " (0, 2, 1, 0, 1, 2),\n",
       " (0, 2, 1, 0, 1, 3),\n",
       " (0, 2, 1, 0, 1, 4),\n",
       " (0, 2, 1, 0, 2, 0),\n",
       " (0, 2, 1, 0, 2, 1),\n",
       " (0, 2, 1, 0, 2, 2),\n",
       " (0, 2, 1, 0, 2, 3),\n",
       " (0, 2, 1, 0, 2, 4),\n",
       " (0, 2, 1, 1, 0, 0),\n",
       " (0, 2, 1, 1, 0, 1),\n",
       " (0, 2, 1, 1, 0, 2),\n",
       " (0, 2, 1, 1, 0, 3),\n",
       " (0, 2, 1, 1, 0, 4),\n",
       " (0, 2, 1, 1, 1, 0),\n",
       " (0, 2, 1, 1, 1, 1),\n",
       " (0, 2, 1, 1, 1, 2),\n",
       " (0, 2, 1, 1, 1, 3),\n",
       " (0, 2, 1, 1, 1, 4),\n",
       " (0, 2, 1, 1, 2, 0),\n",
       " (0, 2, 1, 1, 2, 1),\n",
       " (0, 2, 1, 1, 2, 2),\n",
       " (0, 2, 1, 1, 2, 3),\n",
       " (0, 2, 1, 1, 2, 4),\n",
       " (0, 2, 2, 0, 0, 0),\n",
       " (0, 2, 2, 0, 0, 1),\n",
       " (0, 2, 2, 0, 0, 2),\n",
       " (0, 2, 2, 0, 0, 3),\n",
       " (0, 2, 2, 0, 0, 4),\n",
       " (0, 2, 2, 0, 1, 0),\n",
       " (0, 2, 2, 0, 1, 1),\n",
       " (0, 2, 2, 0, 1, 2),\n",
       " (0, 2, 2, 0, 1, 3),\n",
       " (0, 2, 2, 0, 1, 4),\n",
       " (0, 2, 2, 0, 2, 0),\n",
       " (0, 2, 2, 0, 2, 1),\n",
       " (0, 2, 2, 0, 2, 2),\n",
       " (0, 2, 2, 0, 2, 3),\n",
       " (0, 2, 2, 0, 2, 4),\n",
       " (0, 2, 2, 1, 0, 0),\n",
       " (0, 2, 2, 1, 0, 1),\n",
       " (0, 2, 2, 1, 0, 2),\n",
       " (0, 2, 2, 1, 0, 3),\n",
       " (0, 2, 2, 1, 0, 4),\n",
       " (0, 2, 2, 1, 1, 0),\n",
       " (0, 2, 2, 1, 1, 1),\n",
       " (0, 2, 2, 1, 1, 2),\n",
       " (0, 2, 2, 1, 1, 3),\n",
       " (0, 2, 2, 1, 1, 4),\n",
       " (0, 2, 2, 1, 2, 0),\n",
       " (0, 2, 2, 1, 2, 1),\n",
       " (0, 2, 2, 1, 2, 2),\n",
       " (0, 2, 2, 1, 2, 3),\n",
       " (0, 2, 2, 1, 2, 4),\n",
       " (0, 3, 0, 0, 0, 0),\n",
       " (0, 3, 0, 0, 0, 1),\n",
       " (0, 3, 0, 0, 0, 2),\n",
       " (0, 3, 0, 0, 0, 3),\n",
       " (0, 3, 0, 0, 0, 4),\n",
       " (0, 3, 0, 0, 1, 0),\n",
       " (0, 3, 0, 0, 1, 1),\n",
       " (0, 3, 0, 0, 1, 2),\n",
       " (0, 3, 0, 0, 1, 3),\n",
       " (0, 3, 0, 0, 1, 4),\n",
       " (0, 3, 0, 0, 2, 0),\n",
       " (0, 3, 0, 0, 2, 1),\n",
       " (0, 3, 0, 0, 2, 2),\n",
       " (0, 3, 0, 0, 2, 3),\n",
       " (0, 3, 0, 0, 2, 4),\n",
       " (0, 3, 0, 1, 0, 0),\n",
       " (0, 3, 0, 1, 0, 1),\n",
       " (0, 3, 0, 1, 0, 2),\n",
       " (0, 3, 0, 1, 0, 3),\n",
       " (0, 3, 0, 1, 0, 4),\n",
       " (0, 3, 0, 1, 1, 0),\n",
       " (0, 3, 0, 1, 1, 1),\n",
       " (0, 3, 0, 1, 1, 2),\n",
       " (0, 3, 0, 1, 1, 3),\n",
       " (0, 3, 0, 1, 1, 4),\n",
       " (0, 3, 0, 1, 2, 0),\n",
       " (0, 3, 0, 1, 2, 1),\n",
       " (0, 3, 0, 1, 2, 2),\n",
       " (0, 3, 0, 1, 2, 3),\n",
       " (0, 3, 0, 1, 2, 4),\n",
       " (0, 3, 1, 0, 0, 0),\n",
       " (0, 3, 1, 0, 0, 1),\n",
       " (0, 3, 1, 0, 0, 2),\n",
       " (0, 3, 1, 0, 0, 3),\n",
       " (0, 3, 1, 0, 0, 4),\n",
       " (0, 3, 1, 0, 1, 0),\n",
       " (0, 3, 1, 0, 1, 1),\n",
       " (0, 3, 1, 0, 1, 2),\n",
       " (0, 3, 1, 0, 1, 3),\n",
       " (0, 3, 1, 0, 1, 4),\n",
       " (0, 3, 1, 0, 2, 0),\n",
       " (0, 3, 1, 0, 2, 1),\n",
       " (0, 3, 1, 0, 2, 2),\n",
       " (0, 3, 1, 0, 2, 3),\n",
       " (0, 3, 1, 0, 2, 4),\n",
       " (0, 3, 1, 1, 0, 0),\n",
       " (0, 3, 1, 1, 0, 1),\n",
       " (0, 3, 1, 1, 0, 2),\n",
       " (0, 3, 1, 1, 0, 3),\n",
       " (0, 3, 1, 1, 0, 4),\n",
       " (0, 3, 1, 1, 1, 0),\n",
       " (0, 3, 1, 1, 1, 1),\n",
       " (0, 3, 1, 1, 1, 2),\n",
       " (0, 3, 1, 1, 1, 3),\n",
       " (0, 3, 1, 1, 1, 4),\n",
       " (0, 3, 1, 1, 2, 0),\n",
       " (0, 3, 1, 1, 2, 1),\n",
       " (0, 3, 1, 1, 2, 2),\n",
       " (0, 3, 1, 1, 2, 3),\n",
       " (0, 3, 1, 1, 2, 4),\n",
       " (0, 3, 2, 0, 0, 0),\n",
       " (0, 3, 2, 0, 0, 1),\n",
       " (0, 3, 2, 0, 0, 2),\n",
       " (0, 3, 2, 0, 0, 3),\n",
       " (0, 3, 2, 0, 0, 4),\n",
       " (0, 3, 2, 0, 1, 0),\n",
       " (0, 3, 2, 0, 1, 1),\n",
       " (0, 3, 2, 0, 1, 2),\n",
       " (0, 3, 2, 0, 1, 3),\n",
       " (0, 3, 2, 0, 1, 4),\n",
       " (0, 3, 2, 0, 2, 0),\n",
       " (0, 3, 2, 0, 2, 1),\n",
       " (0, 3, 2, 0, 2, 2),\n",
       " (0, 3, 2, 0, 2, 3),\n",
       " (0, 3, 2, 0, 2, 4),\n",
       " (0, 3, 2, 1, 0, 0),\n",
       " (0, 3, 2, 1, 0, 1),\n",
       " (0, 3, 2, 1, 0, 2),\n",
       " (0, 3, 2, 1, 0, 3),\n",
       " (0, 3, 2, 1, 0, 4),\n",
       " (0, 3, 2, 1, 1, 0),\n",
       " (0, 3, 2, 1, 1, 1),\n",
       " (0, 3, 2, 1, 1, 2),\n",
       " (0, 3, 2, 1, 1, 3),\n",
       " (0, 3, 2, 1, 1, 4),\n",
       " (0, 3, 2, 1, 2, 0),\n",
       " (0, 3, 2, 1, 2, 1),\n",
       " (0, 3, 2, 1, 2, 2),\n",
       " (0, 3, 2, 1, 2, 3),\n",
       " (0, 3, 2, 1, 2, 4),\n",
       " (0, 4, 0, 0, 0, 0),\n",
       " (0, 4, 0, 0, 0, 1),\n",
       " (0, 4, 0, 0, 0, 2),\n",
       " (0, 4, 0, 0, 0, 3),\n",
       " (0, 4, 0, 0, 0, 4),\n",
       " (0, 4, 0, 0, 1, 0),\n",
       " (0, 4, 0, 0, 1, 1),\n",
       " (0, 4, 0, 0, 1, 2),\n",
       " (0, 4, 0, 0, 1, 3),\n",
       " (0, 4, 0, 0, 1, 4),\n",
       " (0, 4, 0, 0, 2, 0),\n",
       " (0, 4, 0, 0, 2, 1),\n",
       " (0, 4, 0, 0, 2, 2),\n",
       " (0, 4, 0, 0, 2, 3),\n",
       " (0, 4, 0, 0, 2, 4),\n",
       " (0, 4, 0, 1, 0, 0),\n",
       " (0, 4, 0, 1, 0, 1),\n",
       " (0, 4, 0, 1, 0, 2),\n",
       " (0, 4, 0, 1, 0, 3),\n",
       " (0, 4, 0, 1, 0, 4),\n",
       " (0, 4, 0, 1, 1, 0),\n",
       " (0, 4, 0, 1, 1, 1),\n",
       " (0, 4, 0, 1, 1, 2),\n",
       " (0, 4, 0, 1, 1, 3),\n",
       " (0, 4, 0, 1, 1, 4),\n",
       " (0, 4, 0, 1, 2, 0),\n",
       " (0, 4, 0, 1, 2, 1),\n",
       " (0, 4, 0, 1, 2, 2),\n",
       " (0, 4, 0, 1, 2, 3),\n",
       " (0, 4, 0, 1, 2, 4),\n",
       " (0, 4, 1, 0, 0, 0),\n",
       " (0, 4, 1, 0, 0, 1),\n",
       " (0, 4, 1, 0, 0, 2),\n",
       " (0, 4, 1, 0, 0, 3),\n",
       " (0, 4, 1, 0, 0, 4),\n",
       " (0, 4, 1, 0, 1, 0),\n",
       " (0, 4, 1, 0, 1, 1),\n",
       " (0, 4, 1, 0, 1, 2),\n",
       " (0, 4, 1, 0, 1, 3),\n",
       " (0, 4, 1, 0, 1, 4),\n",
       " (0, 4, 1, 0, 2, 0),\n",
       " (0, 4, 1, 0, 2, 1),\n",
       " (0, 4, 1, 0, 2, 2),\n",
       " (0, 4, 1, 0, 2, 3),\n",
       " (0, 4, 1, 0, 2, 4),\n",
       " (0, 4, 1, 1, 0, 0),\n",
       " (0, 4, 1, 1, 0, 1),\n",
       " (0, 4, 1, 1, 0, 2),\n",
       " (0, 4, 1, 1, 0, 3),\n",
       " (0, 4, 1, 1, 0, 4),\n",
       " (0, 4, 1, 1, 1, 0),\n",
       " (0, 4, 1, 1, 1, 1),\n",
       " (0, 4, 1, 1, 1, 2),\n",
       " (0, 4, 1, 1, 1, 3),\n",
       " (0, 4, 1, 1, 1, 4),\n",
       " (0, 4, 1, 1, 2, 0),\n",
       " (0, 4, 1, 1, 2, 1),\n",
       " (0, 4, 1, 1, 2, 2),\n",
       " (0, 4, 1, 1, 2, 3),\n",
       " (0, 4, 1, 1, 2, 4),\n",
       " (0, 4, 2, 0, 0, 0),\n",
       " (0, 4, 2, 0, 0, 1),\n",
       " (0, 4, 2, 0, 0, 2),\n",
       " (0, 4, 2, 0, 0, 3),\n",
       " (0, 4, 2, 0, 0, 4),\n",
       " (0, 4, 2, 0, 1, 0),\n",
       " (0, 4, 2, 0, 1, 1),\n",
       " (0, 4, 2, 0, 1, 2),\n",
       " (0, 4, 2, 0, 1, 3),\n",
       " (0, 4, 2, 0, 1, 4),\n",
       " (0, 4, 2, 0, 2, 0),\n",
       " (0, 4, 2, 0, 2, 1),\n",
       " (0, 4, 2, 0, 2, 2),\n",
       " (0, 4, 2, 0, 2, 3),\n",
       " (0, 4, 2, 0, 2, 4),\n",
       " (0, 4, 2, 1, 0, 0),\n",
       " (0, 4, 2, 1, 0, 1),\n",
       " (0, 4, 2, 1, 0, 2),\n",
       " (0, 4, 2, 1, 0, 3),\n",
       " (0, 4, 2, 1, 0, 4),\n",
       " (0, 4, 2, 1, 1, 0),\n",
       " (0, 4, 2, 1, 1, 1),\n",
       " (0, 4, 2, 1, 1, 2),\n",
       " (0, 4, 2, 1, 1, 3),\n",
       " (0, 4, 2, 1, 1, 4),\n",
       " (0, 4, 2, 1, 2, 0),\n",
       " (0, 4, 2, 1, 2, 1),\n",
       " (0, 4, 2, 1, 2, 2),\n",
       " (0, 4, 2, 1, 2, 3),\n",
       " (0, 4, 2, 1, 2, 4),\n",
       " (1, 0, 0, 0, 0, 0),\n",
       " (1, 0, 0, 0, 0, 1),\n",
       " (1, 0, 0, 0, 0, 2),\n",
       " (1, 0, 0, 0, 0, 3),\n",
       " (1, 0, 0, 0, 0, 4),\n",
       " (1, 0, 0, 0, 1, 0),\n",
       " (1, 0, 0, 0, 1, 1),\n",
       " (1, 0, 0, 0, 1, 2),\n",
       " (1, 0, 0, 0, 1, 3),\n",
       " (1, 0, 0, 0, 1, 4),\n",
       " (1, 0, 0, 0, 2, 0),\n",
       " (1, 0, 0, 0, 2, 1),\n",
       " (1, 0, 0, 0, 2, 2),\n",
       " (1, 0, 0, 0, 2, 3),\n",
       " (1, 0, 0, 0, 2, 4),\n",
       " (1, 0, 0, 1, 0, 0),\n",
       " (1, 0, 0, 1, 0, 1),\n",
       " (1, 0, 0, 1, 0, 2),\n",
       " (1, 0, 0, 1, 0, 3),\n",
       " (1, 0, 0, 1, 0, 4),\n",
       " (1, 0, 0, 1, 1, 0),\n",
       " (1, 0, 0, 1, 1, 1),\n",
       " (1, 0, 0, 1, 1, 2),\n",
       " (1, 0, 0, 1, 1, 3),\n",
       " (1, 0, 0, 1, 1, 4),\n",
       " (1, 0, 0, 1, 2, 0),\n",
       " (1, 0, 0, 1, 2, 1),\n",
       " (1, 0, 0, 1, 2, 2),\n",
       " (1, 0, 0, 1, 2, 3),\n",
       " (1, 0, 0, 1, 2, 4),\n",
       " (1, 0, 1, 0, 0, 0),\n",
       " (1, 0, 1, 0, 0, 1),\n",
       " (1, 0, 1, 0, 0, 2),\n",
       " (1, 0, 1, 0, 0, 3),\n",
       " (1, 0, 1, 0, 0, 4),\n",
       " (1, 0, 1, 0, 1, 0),\n",
       " (1, 0, 1, 0, 1, 1),\n",
       " (1, 0, 1, 0, 1, 2),\n",
       " (1, 0, 1, 0, 1, 3),\n",
       " (1, 0, 1, 0, 1, 4),\n",
       " (1, 0, 1, 0, 2, 0),\n",
       " (1, 0, 1, 0, 2, 1),\n",
       " (1, 0, 1, 0, 2, 2),\n",
       " (1, 0, 1, 0, 2, 3),\n",
       " (1, 0, 1, 0, 2, 4),\n",
       " (1, 0, 1, 1, 0, 0),\n",
       " (1, 0, 1, 1, 0, 1),\n",
       " (1, 0, 1, 1, 0, 2),\n",
       " (1, 0, 1, 1, 0, 3),\n",
       " (1, 0, 1, 1, 0, 4),\n",
       " (1, 0, 1, 1, 1, 0),\n",
       " (1, 0, 1, 1, 1, 1),\n",
       " (1, 0, 1, 1, 1, 2),\n",
       " (1, 0, 1, 1, 1, 3),\n",
       " (1, 0, 1, 1, 1, 4),\n",
       " (1, 0, 1, 1, 2, 0),\n",
       " (1, 0, 1, 1, 2, 1),\n",
       " (1, 0, 1, 1, 2, 2),\n",
       " (1, 0, 1, 1, 2, 3),\n",
       " (1, 0, 1, 1, 2, 4),\n",
       " (1, 0, 2, 0, 0, 0),\n",
       " (1, 0, 2, 0, 0, 1),\n",
       " (1, 0, 2, 0, 0, 2),\n",
       " (1, 0, 2, 0, 0, 3),\n",
       " (1, 0, 2, 0, 0, 4),\n",
       " (1, 0, 2, 0, 1, 0),\n",
       " (1, 0, 2, 0, 1, 1),\n",
       " (1, 0, 2, 0, 1, 2),\n",
       " (1, 0, 2, 0, 1, 3),\n",
       " (1, 0, 2, 0, 1, 4),\n",
       " (1, 0, 2, 0, 2, 0),\n",
       " (1, 0, 2, 0, 2, 1),\n",
       " (1, 0, 2, 0, 2, 2),\n",
       " (1, 0, 2, 0, 2, 3),\n",
       " (1, 0, 2, 0, 2, 4),\n",
       " (1, 0, 2, 1, 0, 0),\n",
       " (1, 0, 2, 1, 0, 1),\n",
       " (1, 0, 2, 1, 0, 2),\n",
       " (1, 0, 2, 1, 0, 3),\n",
       " (1, 0, 2, 1, 0, 4),\n",
       " (1, 0, 2, 1, 1, 0),\n",
       " (1, 0, 2, 1, 1, 1),\n",
       " (1, 0, 2, 1, 1, 2),\n",
       " (1, 0, 2, 1, 1, 3),\n",
       " (1, 0, 2, 1, 1, 4),\n",
       " (1, 0, 2, 1, 2, 0),\n",
       " (1, 0, 2, 1, 2, 1),\n",
       " (1, 0, 2, 1, 2, 2),\n",
       " (1, 0, 2, 1, 2, 3),\n",
       " (1, 0, 2, 1, 2, 4),\n",
       " (1, 1, 0, 0, 0, 0),\n",
       " (1, 1, 0, 0, 0, 1),\n",
       " (1, 1, 0, 0, 0, 2),\n",
       " (1, 1, 0, 0, 0, 3),\n",
       " (1, 1, 0, 0, 0, 4),\n",
       " (1, 1, 0, 0, 1, 0),\n",
       " (1, 1, 0, 0, 1, 1),\n",
       " (1, 1, 0, 0, 1, 2),\n",
       " (1, 1, 0, 0, 1, 3),\n",
       " (1, 1, 0, 0, 1, 4),\n",
       " (1, 1, 0, 0, 2, 0),\n",
       " (1, 1, 0, 0, 2, 1),\n",
       " (1, 1, 0, 0, 2, 2),\n",
       " (1, 1, 0, 0, 2, 3),\n",
       " (1, 1, 0, 0, 2, 4),\n",
       " (1, 1, 0, 1, 0, 0),\n",
       " (1, 1, 0, 1, 0, 1),\n",
       " (1, 1, 0, 1, 0, 2),\n",
       " (1, 1, 0, 1, 0, 3),\n",
       " (1, 1, 0, 1, 0, 4),\n",
       " (1, 1, 0, 1, 1, 0),\n",
       " (1, 1, 0, 1, 1, 1),\n",
       " (1, 1, 0, 1, 1, 2),\n",
       " (1, 1, 0, 1, 1, 3),\n",
       " (1, 1, 0, 1, 1, 4),\n",
       " (1, 1, 0, 1, 2, 0),\n",
       " (1, 1, 0, 1, 2, 1),\n",
       " (1, 1, 0, 1, 2, 2),\n",
       " (1, 1, 0, 1, 2, 3),\n",
       " (1, 1, 0, 1, 2, 4),\n",
       " (1, 1, 1, 0, 0, 0),\n",
       " (1, 1, 1, 0, 0, 1),\n",
       " (1, 1, 1, 0, 0, 2),\n",
       " (1, 1, 1, 0, 0, 3),\n",
       " (1, 1, 1, 0, 0, 4),\n",
       " (1, 1, 1, 0, 1, 0),\n",
       " (1, 1, 1, 0, 1, 1),\n",
       " (1, 1, 1, 0, 1, 2),\n",
       " (1, 1, 1, 0, 1, 3),\n",
       " (1, 1, 1, 0, 1, 4),\n",
       " (1, 1, 1, 0, 2, 0),\n",
       " (1, 1, 1, 0, 2, 1),\n",
       " (1, 1, 1, 0, 2, 2),\n",
       " (1, 1, 1, 0, 2, 3),\n",
       " (1, 1, 1, 0, 2, 4),\n",
       " (1, 1, 1, 1, 0, 0),\n",
       " (1, 1, 1, 1, 0, 1),\n",
       " (1, 1, 1, 1, 0, 2),\n",
       " (1, 1, 1, 1, 0, 3),\n",
       " (1, 1, 1, 1, 0, 4),\n",
       " (1, 1, 1, 1, 1, 0),\n",
       " (1, 1, 1, 1, 1, 1),\n",
       " (1, 1, 1, 1, 1, 2),\n",
       " (1, 1, 1, 1, 1, 3),\n",
       " (1, 1, 1, 1, 1, 4),\n",
       " (1, 1, 1, 1, 2, 0),\n",
       " (1, 1, 1, 1, 2, 1),\n",
       " (1, 1, 1, 1, 2, 2),\n",
       " (1, 1, 1, 1, 2, 3),\n",
       " (1, 1, 1, 1, 2, 4),\n",
       " (1, 1, 2, 0, 0, 0),\n",
       " (1, 1, 2, 0, 0, 1),\n",
       " (1, 1, 2, 0, 0, 2),\n",
       " (1, 1, 2, 0, 0, 3),\n",
       " (1, 1, 2, 0, 0, 4),\n",
       " (1, 1, 2, 0, 1, 0),\n",
       " (1, 1, 2, 0, 1, 1),\n",
       " (1, 1, 2, 0, 1, 2),\n",
       " (1, 1, 2, 0, 1, 3),\n",
       " (1, 1, 2, 0, 1, 4),\n",
       " (1, 1, 2, 0, 2, 0),\n",
       " (1, 1, 2, 0, 2, 1),\n",
       " (1, 1, 2, 0, 2, 2),\n",
       " (1, 1, 2, 0, 2, 3),\n",
       " (1, 1, 2, 0, 2, 4),\n",
       " (1, 1, 2, 1, 0, 0),\n",
       " (1, 1, 2, 1, 0, 1),\n",
       " (1, 1, 2, 1, 0, 2),\n",
       " (1, 1, 2, 1, 0, 3),\n",
       " (1, 1, 2, 1, 0, 4),\n",
       " (1, 1, 2, 1, 1, 0),\n",
       " (1, 1, 2, 1, 1, 1),\n",
       " (1, 1, 2, 1, 1, 2),\n",
       " (1, 1, 2, 1, 1, 3),\n",
       " (1, 1, 2, 1, 1, 4),\n",
       " (1, 1, 2, 1, 2, 0),\n",
       " (1, 1, 2, 1, 2, 1),\n",
       " (1, 1, 2, 1, 2, 2),\n",
       " (1, 1, 2, 1, 2, 3),\n",
       " (1, 1, 2, 1, 2, 4),\n",
       " (1, 2, 0, 0, 0, 0),\n",
       " (1, 2, 0, 0, 0, 1),\n",
       " (1, 2, 0, 0, 0, 2),\n",
       " (1, 2, 0, 0, 0, 3),\n",
       " (1, 2, 0, 0, 0, 4),\n",
       " (1, 2, 0, 0, 1, 0),\n",
       " (1, 2, 0, 0, 1, 1),\n",
       " (1, 2, 0, 0, 1, 2),\n",
       " (1, 2, 0, 0, 1, 3),\n",
       " (1, 2, 0, 0, 1, 4),\n",
       " (1, 2, 0, 0, 2, 0),\n",
       " (1, 2, 0, 0, 2, 1),\n",
       " (1, 2, 0, 0, 2, 2),\n",
       " (1, 2, 0, 0, 2, 3),\n",
       " (1, 2, 0, 0, 2, 4),\n",
       " (1, 2, 0, 1, 0, 0),\n",
       " (1, 2, 0, 1, 0, 1),\n",
       " (1, 2, 0, 1, 0, 2),\n",
       " (1, 2, 0, 1, 0, 3),\n",
       " (1, 2, 0, 1, 0, 4),\n",
       " (1, 2, 0, 1, 1, 0),\n",
       " (1, 2, 0, 1, 1, 1),\n",
       " (1, 2, 0, 1, 1, 2),\n",
       " (1, 2, 0, 1, 1, 3),\n",
       " (1, 2, 0, 1, 1, 4),\n",
       " (1, 2, 0, 1, 2, 0),\n",
       " (1, 2, 0, 1, 2, 1),\n",
       " (1, 2, 0, 1, 2, 2),\n",
       " (1, 2, 0, 1, 2, 3),\n",
       " (1, 2, 0, 1, 2, 4),\n",
       " (1, 2, 1, 0, 0, 0),\n",
       " (1, 2, 1, 0, 0, 1),\n",
       " (1, 2, 1, 0, 0, 2),\n",
       " (1, 2, 1, 0, 0, 3),\n",
       " (1, 2, 1, 0, 0, 4),\n",
       " (1, 2, 1, 0, 1, 0),\n",
       " (1, 2, 1, 0, 1, 1),\n",
       " (1, 2, 1, 0, 1, 2),\n",
       " (1, 2, 1, 0, 1, 3),\n",
       " (1, 2, 1, 0, 1, 4),\n",
       " (1, 2, 1, 0, 2, 0),\n",
       " (1, 2, 1, 0, 2, 1),\n",
       " (1, 2, 1, 0, 2, 2),\n",
       " (1, 2, 1, 0, 2, 3),\n",
       " (1, 2, 1, 0, 2, 4),\n",
       " (1, 2, 1, 1, 0, 0),\n",
       " (1, 2, 1, 1, 0, 1),\n",
       " (1, 2, 1, 1, 0, 2),\n",
       " (1, 2, 1, 1, 0, 3),\n",
       " (1, 2, 1, 1, 0, 4),\n",
       " (1, 2, 1, 1, 1, 0),\n",
       " (1, 2, 1, 1, 1, 1),\n",
       " (1, 2, 1, 1, 1, 2),\n",
       " (1, 2, 1, 1, 1, 3),\n",
       " (1, 2, 1, 1, 1, 4),\n",
       " (1, 2, 1, 1, 2, 0),\n",
       " (1, 2, 1, 1, 2, 1),\n",
       " (1, 2, 1, 1, 2, 2),\n",
       " (1, 2, 1, 1, 2, 3),\n",
       " (1, 2, 1, 1, 2, 4),\n",
       " (1, 2, 2, 0, 0, 0),\n",
       " (1, 2, 2, 0, 0, 1),\n",
       " (1, 2, 2, 0, 0, 2),\n",
       " (1, 2, 2, 0, 0, 3),\n",
       " (1, 2, 2, 0, 0, 4),\n",
       " (1, 2, 2, 0, 1, 0),\n",
       " (1, 2, 2, 0, 1, 1),\n",
       " (1, 2, 2, 0, 1, 2),\n",
       " (1, 2, 2, 0, 1, 3),\n",
       " (1, 2, 2, 0, 1, 4),\n",
       " (1, 2, 2, 0, 2, 0),\n",
       " (1, 2, 2, 0, 2, 1),\n",
       " (1, 2, 2, 0, 2, 2),\n",
       " (1, 2, 2, 0, 2, 3),\n",
       " (1, 2, 2, 0, 2, 4),\n",
       " (1, 2, 2, 1, 0, 0),\n",
       " (1, 2, 2, 1, 0, 1),\n",
       " (1, 2, 2, 1, 0, 2),\n",
       " (1, 2, 2, 1, 0, 3),\n",
       " (1, 2, 2, 1, 0, 4),\n",
       " (1, 2, 2, 1, 1, 0),\n",
       " (1, 2, 2, 1, 1, 1),\n",
       " (1, 2, 2, 1, 1, 2),\n",
       " (1, 2, 2, 1, 1, 3),\n",
       " (1, 2, 2, 1, 1, 4),\n",
       " (1, 2, 2, 1, 2, 0),\n",
       " (1, 2, 2, 1, 2, 1),\n",
       " (1, 2, 2, 1, 2, 2),\n",
       " (1, 2, 2, 1, 2, 3),\n",
       " (1, 2, 2, 1, 2, 4),\n",
       " (1, 3, 0, 0, 0, 0),\n",
       " (1, 3, 0, 0, 0, 1),\n",
       " (1, 3, 0, 0, 0, 2),\n",
       " (1, 3, 0, 0, 0, 3),\n",
       " (1, 3, 0, 0, 0, 4),\n",
       " (1, 3, 0, 0, 1, 0),\n",
       " (1, 3, 0, 0, 1, 1),\n",
       " (1, 3, 0, 0, 1, 2),\n",
       " (1, 3, 0, 0, 1, 3),\n",
       " (1, 3, 0, 0, 1, 4),\n",
       " (1, 3, 0, 0, 2, 0),\n",
       " (1, 3, 0, 0, 2, 1),\n",
       " (1, 3, 0, 0, 2, 2),\n",
       " (1, 3, 0, 0, 2, 3),\n",
       " (1, 3, 0, 0, 2, 4),\n",
       " (1, 3, 0, 1, 0, 0),\n",
       " (1, 3, 0, 1, 0, 1),\n",
       " (1, 3, 0, 1, 0, 2),\n",
       " (1, 3, 0, 1, 0, 3),\n",
       " (1, 3, 0, 1, 0, 4),\n",
       " (1, 3, 0, 1, 1, 0),\n",
       " (1, 3, 0, 1, 1, 1),\n",
       " (1, 3, 0, 1, 1, 2),\n",
       " (1, 3, 0, 1, 1, 3),\n",
       " (1, 3, 0, 1, 1, 4),\n",
       " (1, 3, 0, 1, 2, 0),\n",
       " (1, 3, 0, 1, 2, 1),\n",
       " (1, 3, 0, 1, 2, 2),\n",
       " (1, 3, 0, 1, 2, 3),\n",
       " (1, 3, 0, 1, 2, 4),\n",
       " (1, 3, 1, 0, 0, 0),\n",
       " (1, 3, 1, 0, 0, 1),\n",
       " (1, 3, 1, 0, 0, 2),\n",
       " (1, 3, 1, 0, 0, 3),\n",
       " (1, 3, 1, 0, 0, 4),\n",
       " (1, 3, 1, 0, 1, 0),\n",
       " (1, 3, 1, 0, 1, 1),\n",
       " (1, 3, 1, 0, 1, 2),\n",
       " (1, 3, 1, 0, 1, 3),\n",
       " (1, 3, 1, 0, 1, 4),\n",
       " (1, 3, 1, 0, 2, 0),\n",
       " (1, 3, 1, 0, 2, 1),\n",
       " (1, 3, 1, 0, 2, 2),\n",
       " (1, 3, 1, 0, 2, 3),\n",
       " (1, 3, 1, 0, 2, 4),\n",
       " (1, 3, 1, 1, 0, 0),\n",
       " (1, 3, 1, 1, 0, 1),\n",
       " (1, 3, 1, 1, 0, 2),\n",
       " (1, 3, 1, 1, 0, 3),\n",
       " (1, 3, 1, 1, 0, 4),\n",
       " (1, 3, 1, 1, 1, 0),\n",
       " (1, 3, 1, 1, 1, 1),\n",
       " (1, 3, 1, 1, 1, 2),\n",
       " (1, 3, 1, 1, 1, 3),\n",
       " (1, 3, 1, 1, 1, 4),\n",
       " (1, 3, 1, 1, 2, 0),\n",
       " (1, 3, 1, 1, 2, 1),\n",
       " (1, 3, 1, 1, 2, 2),\n",
       " (1, 3, 1, 1, 2, 3),\n",
       " (1, 3, 1, 1, 2, 4),\n",
       " (1, 3, 2, 0, 0, 0),\n",
       " (1, 3, 2, 0, 0, 1),\n",
       " (1, 3, 2, 0, 0, 2),\n",
       " (1, 3, 2, 0, 0, 3),\n",
       " (1, 3, 2, 0, 0, 4),\n",
       " (1, 3, 2, 0, 1, 0),\n",
       " (1, 3, 2, 0, 1, 1),\n",
       " (1, 3, 2, 0, 1, 2),\n",
       " (1, 3, 2, 0, 1, 3),\n",
       " (1, 3, 2, 0, 1, 4),\n",
       " (1, 3, 2, 0, 2, 0),\n",
       " (1, 3, 2, 0, 2, 1),\n",
       " (1, 3, 2, 0, 2, 2),\n",
       " (1, 3, 2, 0, 2, 3),\n",
       " (1, 3, 2, 0, 2, 4),\n",
       " (1, 3, 2, 1, 0, 0),\n",
       " (1, 3, 2, 1, 0, 1),\n",
       " (1, 3, 2, 1, 0, 2),\n",
       " (1, 3, 2, 1, 0, 3),\n",
       " (1, 3, 2, 1, 0, 4),\n",
       " (1, 3, 2, 1, 1, 0),\n",
       " (1, 3, 2, 1, 1, 1),\n",
       " (1, 3, 2, 1, 1, 2),\n",
       " (1, 3, 2, 1, 1, 3),\n",
       " (1, 3, 2, 1, 1, 4),\n",
       " (1, 3, 2, 1, 2, 0),\n",
       " (1, 3, 2, 1, 2, 1),\n",
       " (1, 3, 2, 1, 2, 2),\n",
       " (1, 3, 2, 1, 2, 3),\n",
       " (1, 3, 2, 1, 2, 4),\n",
       " (1, 4, 0, 0, 0, 0),\n",
       " (1, 4, 0, 0, 0, 1),\n",
       " (1, 4, 0, 0, 0, 2),\n",
       " (1, 4, 0, 0, 0, 3),\n",
       " (1, 4, 0, 0, 0, 4),\n",
       " (1, 4, 0, 0, 1, 0),\n",
       " (1, 4, 0, 0, 1, 1),\n",
       " (1, 4, 0, 0, 1, 2),\n",
       " (1, 4, 0, 0, 1, 3),\n",
       " (1, 4, 0, 0, 1, 4),\n",
       " (1, 4, 0, 0, 2, 0),\n",
       " (1, 4, 0, 0, 2, 1),\n",
       " (1, 4, 0, 0, 2, 2),\n",
       " (1, 4, 0, 0, 2, 3),\n",
       " (1, 4, 0, 0, 2, 4),\n",
       " (1, 4, 0, 1, 0, 0),\n",
       " (1, 4, 0, 1, 0, 1),\n",
       " (1, 4, 0, 1, 0, 2),\n",
       " (1, 4, 0, 1, 0, 3),\n",
       " (1, 4, 0, 1, 0, 4),\n",
       " (1, 4, 0, 1, 1, 0),\n",
       " (1, 4, 0, 1, 1, 1),\n",
       " (1, 4, 0, 1, 1, 2),\n",
       " (1, 4, 0, 1, 1, 3),\n",
       " (1, 4, 0, 1, 1, 4),\n",
       " (1, 4, 0, 1, 2, 0),\n",
       " (1, 4, 0, 1, 2, 1),\n",
       " (1, 4, 0, 1, 2, 2),\n",
       " (1, 4, 0, 1, 2, 3),\n",
       " (1, 4, 0, 1, 2, 4),\n",
       " (1, 4, 1, 0, 0, 0),\n",
       " (1, 4, 1, 0, 0, 1),\n",
       " (1, 4, 1, 0, 0, 2),\n",
       " (1, 4, 1, 0, 0, 3),\n",
       " (1, 4, 1, 0, 0, 4),\n",
       " (1, 4, 1, 0, 1, 0),\n",
       " (1, 4, 1, 0, 1, 1),\n",
       " (1, 4, 1, 0, 1, 2),\n",
       " (1, 4, 1, 0, 1, 3),\n",
       " (1, 4, 1, 0, 1, 4),\n",
       " (1, 4, 1, 0, 2, 0),\n",
       " (1, 4, 1, 0, 2, 1),\n",
       " (1, 4, 1, 0, 2, 2),\n",
       " (1, 4, 1, 0, 2, 3),\n",
       " (1, 4, 1, 0, 2, 4),\n",
       " (1, 4, 1, 1, 0, 0),\n",
       " (1, 4, 1, 1, 0, 1),\n",
       " (1, 4, 1, 1, 0, 2),\n",
       " (1, 4, 1, 1, 0, 3),\n",
       " (1, 4, 1, 1, 0, 4),\n",
       " (1, 4, 1, 1, 1, 0),\n",
       " (1, 4, 1, 1, 1, 1),\n",
       " (1, 4, 1, 1, 1, 2),\n",
       " (1, 4, 1, 1, 1, 3),\n",
       " (1, 4, 1, 1, 1, 4),\n",
       " (1, 4, 1, 1, 2, 0),\n",
       " (1, 4, 1, 1, 2, 1),\n",
       " (1, 4, 1, 1, 2, 2),\n",
       " (1, 4, 1, 1, 2, 3),\n",
       " (1, 4, 1, 1, 2, 4),\n",
       " (1, 4, 2, 0, 0, 0),\n",
       " (1, 4, 2, 0, 0, 1),\n",
       " (1, 4, 2, 0, 0, 2),\n",
       " (1, 4, 2, 0, 0, 3),\n",
       " (1, 4, 2, 0, 0, 4),\n",
       " (1, 4, 2, 0, 1, 0),\n",
       " (1, 4, 2, 0, 1, 1),\n",
       " (1, 4, 2, 0, 1, 2),\n",
       " (1, 4, 2, 0, 1, 3),\n",
       " (1, 4, 2, 0, 1, 4),\n",
       " (1, 4, 2, 0, 2, 0),\n",
       " (1, 4, 2, 0, 2, 1),\n",
       " (1, 4, 2, 0, 2, 2),\n",
       " (1, 4, 2, 0, 2, 3),\n",
       " (1, 4, 2, 0, 2, 4),\n",
       " (1, 4, 2, 1, 0, 0),\n",
       " (1, 4, 2, 1, 0, 1),\n",
       " (1, 4, 2, 1, 0, 2),\n",
       " (1, 4, 2, 1, 0, 3),\n",
       " (1, 4, 2, 1, 0, 4),\n",
       " (1, 4, 2, 1, 1, 0),\n",
       " (1, 4, 2, 1, 1, 1),\n",
       " (1, 4, 2, 1, 1, 2),\n",
       " (1, 4, 2, 1, 1, 3),\n",
       " (1, 4, 2, 1, 1, 4),\n",
       " (1, 4, 2, 1, 2, 0),\n",
       " (1, 4, 2, 1, 2, 1),\n",
       " (1, 4, 2, 1, 2, 2),\n",
       " (1, 4, 2, 1, 2, 3),\n",
       " (1, 4, 2, 1, 2, 4),\n",
       " (2, 0, 0, 0, 0, 0),\n",
       " (2, 0, 0, 0, 0, 1),\n",
       " (2, 0, 0, 0, 0, 2),\n",
       " (2, 0, 0, 0, 0, 3),\n",
       " (2, 0, 0, 0, 0, 4),\n",
       " (2, 0, 0, 0, 1, 0),\n",
       " (2, 0, 0, 0, 1, 1),\n",
       " (2, 0, 0, 0, 1, 2),\n",
       " (2, 0, 0, 0, 1, 3),\n",
       " (2, 0, 0, 0, 1, 4),\n",
       " (2, 0, 0, 0, 2, 0),\n",
       " (2, 0, 0, 0, 2, 1),\n",
       " (2, 0, 0, 0, 2, 2),\n",
       " (2, 0, 0, 0, 2, 3),\n",
       " (2, 0, 0, 0, 2, 4),\n",
       " (2, 0, 0, 1, 0, 0),\n",
       " (2, 0, 0, 1, 0, 1),\n",
       " (2, 0, 0, 1, 0, 2),\n",
       " (2, 0, 0, 1, 0, 3),\n",
       " (2, 0, 0, 1, 0, 4),\n",
       " (2, 0, 0, 1, 1, 0),\n",
       " (2, 0, 0, 1, 1, 1),\n",
       " (2, 0, 0, 1, 1, 2),\n",
       " (2, 0, 0, 1, 1, 3),\n",
       " (2, 0, 0, 1, 1, 4),\n",
       " (2, 0, 0, 1, 2, 0),\n",
       " (2, 0, 0, 1, 2, 1),\n",
       " (2, 0, 0, 1, 2, 2),\n",
       " (2, 0, 0, 1, 2, 3),\n",
       " (2, 0, 0, 1, 2, 4),\n",
       " (2, 0, 1, 0, 0, 0),\n",
       " (2, 0, 1, 0, 0, 1),\n",
       " (2, 0, 1, 0, 0, 2),\n",
       " (2, 0, 1, 0, 0, 3),\n",
       " (2, 0, 1, 0, 0, 4),\n",
       " (2, 0, 1, 0, 1, 0),\n",
       " (2, 0, 1, 0, 1, 1),\n",
       " (2, 0, 1, 0, 1, 2),\n",
       " (2, 0, 1, 0, 1, 3),\n",
       " (2, 0, 1, 0, 1, 4),\n",
       " (2, 0, 1, 0, 2, 0),\n",
       " (2, 0, 1, 0, 2, 1),\n",
       " (2, 0, 1, 0, 2, 2),\n",
       " (2, 0, 1, 0, 2, 3),\n",
       " (2, 0, 1, 0, 2, 4),\n",
       " (2, 0, 1, 1, 0, 0),\n",
       " (2, 0, 1, 1, 0, 1),\n",
       " (2, 0, 1, 1, 0, 2),\n",
       " (2, 0, 1, 1, 0, 3),\n",
       " (2, 0, 1, 1, 0, 4),\n",
       " (2, 0, 1, 1, 1, 0),\n",
       " (2, 0, 1, 1, 1, 1),\n",
       " (2, 0, 1, 1, 1, 2),\n",
       " (2, 0, 1, 1, 1, 3),\n",
       " (2, 0, 1, 1, 1, 4),\n",
       " (2, 0, 1, 1, 2, 0),\n",
       " (2, 0, 1, 1, 2, 1),\n",
       " (2, 0, 1, 1, 2, 2),\n",
       " (2, 0, 1, 1, 2, 3),\n",
       " (2, 0, 1, 1, 2, 4),\n",
       " (2, 0, 2, 0, 0, 0),\n",
       " (2, 0, 2, 0, 0, 1),\n",
       " (2, 0, 2, 0, 0, 2),\n",
       " (2, 0, 2, 0, 0, 3),\n",
       " (2, 0, 2, 0, 0, 4),\n",
       " (2, 0, 2, 0, 1, 0),\n",
       " (2, 0, 2, 0, 1, 1),\n",
       " (2, 0, 2, 0, 1, 2),\n",
       " (2, 0, 2, 0, 1, 3),\n",
       " (2, 0, 2, 0, 1, 4),\n",
       " (2, 0, 2, 0, 2, 0),\n",
       " (2, 0, 2, 0, 2, 1),\n",
       " (2, 0, 2, 0, 2, 2),\n",
       " (2, 0, 2, 0, 2, 3),\n",
       " (2, 0, 2, 0, 2, 4),\n",
       " (2, 0, 2, 1, 0, 0),\n",
       " (2, 0, 2, 1, 0, 1),\n",
       " (2, 0, 2, 1, 0, 2),\n",
       " (2, 0, 2, 1, 0, 3),\n",
       " (2, 0, 2, 1, 0, 4),\n",
       " (2, 0, 2, 1, 1, 0),\n",
       " (2, 0, 2, 1, 1, 1),\n",
       " (2, 0, 2, 1, 1, 2),\n",
       " (2, 0, 2, 1, 1, 3),\n",
       " (2, 0, 2, 1, 1, 4),\n",
       " (2, 0, 2, 1, 2, 0),\n",
       " (2, 0, 2, 1, 2, 1),\n",
       " (2, 0, 2, 1, 2, 2),\n",
       " (2, 0, 2, 1, 2, 3),\n",
       " (2, 0, 2, 1, 2, 4),\n",
       " (2, 1, 0, 0, 0, 0),\n",
       " (2, 1, 0, 0, 0, 1),\n",
       " (2, 1, 0, 0, 0, 2),\n",
       " (2, 1, 0, 0, 0, 3),\n",
       " (2, 1, 0, 0, 0, 4),\n",
       " (2, 1, 0, 0, 1, 0),\n",
       " (2, 1, 0, 0, 1, 1),\n",
       " (2, 1, 0, 0, 1, 2),\n",
       " (2, 1, 0, 0, 1, 3),\n",
       " (2, 1, 0, 0, 1, 4),\n",
       " ...]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cac87174",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {'gamma' : [0.95,0.99],\n",
    "           'lr' : [0.05,0.1,0.2],\n",
    "           'eps_start' : np.arange(.7,1.1,.1).tolist(),\n",
    "           'eps_end' : [0.001,0.01,0.1],\n",
    "           'decay' : [.99,.999,.9999],\n",
    "           'repeats': range(5)}\n",
    "\n",
    "combs = list(product(*[range(len(i)) for i in list(hparams.values())]))\n",
    "scores = np.zeros([len(i) for i in list(hparams.values())])\n",
    "\n",
    "\n",
    "for comb_indexes in combs:\n",
    "    comb_values = {name:val[idx] for name,val,idx in zip(hparams.keys(),hparams.values(),comb_indexes)}\n",
    "    score = 1\n",
    "    scores[tuple(comb_indexes)] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5f9898b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.99,\n",
       " 'lr': 0.2,\n",
       " 'eps_start': 1.0999999999999999,\n",
       " 'eps_end': 0.1,\n",
       " 'decay': 0.9999,\n",
       " 'repeats': 4}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c8bca669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5107df7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.95 0.05 0.7 0.001 0.99 0.0'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ddfaed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.95', '0.05', '0.7', '0.001', '0.99', '0.0'], dtype='<U32')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "828a71a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "       [[[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]]],\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "       [[[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]],\n",
       "\n",
       "          [[1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1., 1.]]]]]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "6250->500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "928de51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(11000//16)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f9e9545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100b76b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
